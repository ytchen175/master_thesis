{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/wirl/anaconda3/envs/s_paper/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/wirl/anaconda3/envs/s_paper/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wirl/anaconda3/envs/s_paper/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/wirl/anaconda3 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/wirl/anaconda3/envs/s_paper/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda-10.1/lib64')}\n",
      "  warn(msg)\n",
      "/home/wirl/anaconda3/envs/s_paper/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/cuda-10.1/lib64: did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/wirl/anaconda3/envs/s_paper/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/wirl/anaconda3/envs/s_paper/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/wirl/anaconda3/envs/s_paper/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n",
      "  warn(msg)\n",
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96656f53822d4807af9514c5d1150f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3080 Ti\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoModelForCausalLM, LlamaTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftModel # PEFT = Parameter-Efficient Fine-Tuning\n",
    "from trl import SFTTrainer # trl = Transformer Reinforcement Learning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# base model: https://github.com/ymcui/Chinese-LLaMA-Alpaca-2\n",
    "model_name = \"/home/wirl/ytc/chinese-alpaca-2-7b_自己下載的\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name, local_files_only=True, legacy=True)\n",
    "\n",
    "# 7B 沒辦法不 quantize 跑\n",
    "# 8bit 的無法 fine tune\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "# )\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, local_files_only=True, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, local_files_only=True, load_in_4bit=True, device_map=\"auto\", pretraining_tp=1)\n",
    "model.config.use_cache = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(model, prompt_template, sentence_text, remove_input=True):\n",
    "    device = \"cuda:0\"\n",
    "    full_prompt = prompt_template.format(sentence_text)\n",
    "\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # outputs = model.generate(**inputs, max_new_tokens=len(sentence_text))\n",
    "    outputs = model.generate(**inputs, max_new_tokens=len(sentence_text), do_sample=True, top_k=30, top_p=0.95, num_return_sequences=1) # for translation, https://huggingface.co/docs/transformers/tasks/translation#inference\n",
    "\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    if remove_input:\n",
    "        # 從 generate 出來的 output 中刪除 input text 的部分\n",
    "        cleaned_output = decoded_output.replace(full_prompt, \"\")\n",
    "        return cleaned_output\n",
    "    else:\n",
    "        return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神品、妙品、能品是中国古代品评书画艺术的重要等级。在古代，品评书画的等级非常重要\n",
      "---\n",
      "台中后里位在台湾南北的交会点，隐藏着许多全国知名的景点。\n",
      "---\n",
      "你干嘛不把这些事情留给我来做\n",
      "---\n",
      "太后的头发很干燥，我应该做些什么？\n",
      "\n",
      "---\n",
      "芋头发芽了\n",
      "---\n",
      "为什么头发？电脑会吸走了我的头发？@@\n",
      "### Instruction: \n",
      "---\n",
      "他觉得丑时人生的通常都比较丑。 他觉得丑时\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# 先看一下還沒 tune 之前的效果，不能翻譯\n",
    "sentence = \"我国古代品评书画艺术的三个等级，即神品、妙品、能品。\"\n",
    "sentence1 = \"台中后里位在台湾南北的交会点，隐藏着许多全国知名的景点。\"\n",
    "sentence2 = \"我干什么不干你事。\"\n",
    "sentence3 = \"我发现太后的头发很干燥。\"\n",
    "sentence4 = \"芋头发芽了。\"\n",
    "sentence5 = \"再坐在电脑前面 我头发都没了T_T。\"\n",
    "sentence6 = \"他觉得丑时人生的通常都比较丑。\"\n",
    "\n",
    "translate_prompt_template = \"\"\"\n",
    "### Instruction:\n",
    "翻譯成繁體中文: {}\n",
    "### Response:\n",
    "\"\"\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "print(get_response(model, translate_prompt_template, sentence))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence1))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence2))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence3))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence4))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence5))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence6))\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stanford_alpaca 的 prompt template\n",
    "# ref: https://zhuanlan.zhihu.com/p/647149346\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{}\\n\\n### Input:\\n{}\\n\\n### Response:{}\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{}\\n\\n### Response:{}\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "def format_instruction_prompt(example):\n",
    "    output_texts = []\n",
    "\n",
    "    for i in range(len(example['instruction'])):\n",
    "        if example[\"input\"]:\n",
    "            text = PROMPT_DICT['prompt_input'].format(example[\"instruction\"][i], example[\"input\"][i], example[\"output\"][i])\n",
    "        else:\n",
    "            text = PROMPT_DICT['prompt_no_input'].format(example[\"instruction\"][i], example[\"output\"][i])\n",
    "        output_texts.append(text)\n",
    "\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-179e62d222f253db\n",
      "Found cached dataset csv (/home/wirl/.cache/huggingface/datasets/csv/default-179e62d222f253db/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train dataset---\n",
      "Dataset({\n",
      "    features: ['category', 'instruction', 'input', 'output'],\n",
      "    num_rows: 365461\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# dataset = load_dataset(\"csv\", data_files='instruction_datasets/chinese_cultural_history.csv', split='train')\n",
    "train_dataset = load_dataset(\"csv\", data_files='instruction_datasets/ministry_of_education_revised_dictionary.csv', split='train')\n",
    "\n",
    "print(\"---Train dataset---\")\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 453251072 || all params: 3691253760 || trainable%: 12.2790548000688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wirl/.cache/huggingface/datasets/csv/default-179e62d222f253db/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-5a2bbf1ca41b6a7c.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 05:45, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.835300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.575400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.815200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.155800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.684000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from peft import prepare_model_for_kbit_training\n",
    "\n",
    "save_lora = True\n",
    "\n",
    "\"\"\"--- Training arguments ---\"\"\"\n",
    "output_dir = \"./results\"\n",
    "\n",
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "optim = \"paged_adamw_32bit\"\n",
    "save_steps = 100\n",
    "logging_steps = 10\n",
    "learning_rate = 2e-4\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 100\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"none\" # don't want to use wandb\n",
    ")\n",
    "\n",
    "\"\"\"--- LoRA config ---\"\"\"\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "\n",
    "\"\"\"--- SFT Trainer (Supervised Fine-tuning Trainer) ---\"\"\"\n",
    "max_seq_length = 512\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    formatting_func=format_instruction_prompt,\n",
    "    peft_config=lora_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "\n",
    "for name, module in trainer.model.named_modules():\n",
    "    if \"norm\" in name:\n",
    "        # module = module.to(torch.float32)\n",
    "        module = module.to(torch.float16)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "if save_lora:\n",
    "    now = datetime.now()\n",
    "    # dt_string = now.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    lora_adapter_name = \"chinese_alpaca2_lora\"\n",
    "\n",
    "    # save adapter only\n",
    "    output_path = os.path.join(output_dir, lora_adapter_name)\n",
    "\n",
    "    trainer.model.save_pretrained(output_path)\n",
    "    tokenizer.save_pretrained(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我國古代品評書畫藝術的三個等級，即神品、妙品、能品。\n",
      "##\n",
      "---\n",
      "台中後里位在台灣南北的交會點，隱藏著許多全國知名的景點。\n",
      "\n",
      "### Inst\n",
      "---\n",
      "為什麼不處理那些不是你事兒\n",
      "---\n",
      "我發現太后的頭髮很乾燥。\n",
      "\n",
      "---\n",
      "芋头发芽了。\n",
      "---\n",
      "再坐在電腦前面。我頭髮都沒了T_T。\n",
      "###\n",
      "---\n",
      "他認為醜時的人生的通常都很醜。\n",
      "### Instruction\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# 剛 tune 完所以要可以翻譯\n",
    "sentence = \"我国古代品评书画艺术的三个等级，即神品、妙品、能品。\"\n",
    "sentence1 = \"台中后里位在台湾南北的交会点，隐藏着许多全国知名的景点。\"\n",
    "sentence2 = \"我干什么不干你事。\"\n",
    "sentence3 = \"我发现太后的头发很干燥。\"\n",
    "sentence4 = \"芋头发芽了。\"\n",
    "sentence5 = \"再坐在电脑前面 我头发都没了T_T。\"\n",
    "sentence6 = \"他觉得丑时人生的通常都比较丑。\"\n",
    "\n",
    "translate_prompt_template = \"\"\"\n",
    "### Instruction:\n",
    "翻譯成繁體中文: {}\n",
    "### Response:\n",
    "\"\"\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "print(get_response(model, translate_prompt_template, sentence))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence1))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence2))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence3))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence4))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence5))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence6))\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "\n",
    "# lora_adapter_name = f\"chinese_alpaca2_{dt_string}\"\n",
    "# lora_adapter_name = \"chinese_alpaca2_2023_09_10-13_42_45\"\n",
    "# lora_adapter_name = \"chinese_alpaca2_2023_09_18-15_40_56\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cf281c7c8a4ba3a2fbf2e07114dec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lora_adapter_path = f\"/home/wirl/ytc/要寫的論文研究/code/results/{lora_adapter_name}\"\n",
    "save_tuned_model_path = \"/home/wirl/ytc/要寫的論文研究/code/results/chinese-alpaca-2-7b_merged_tuned_model/\"\n",
    "\n",
    "llama2_base_model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                        device_map={\"\": \"cpu\"}, \n",
    "                        torch_dtype=torch.float16)\n",
    "\n",
    "model = PeftModel.from_pretrained(llama2_base_model, \n",
    "                        lora_adapter_path, \n",
    "                        torch_dtype=torch.float16, \n",
    "                        device_map={\"\": \"cpu\"})\n",
    "\n",
    "del llama2_base_model\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "merged_model.save_pretrained(save_tuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del merged_model\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f4731d0b0b4277ab50c80fcaffaa13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reload model from merged model path\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    save_tuned_model_path,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(model, prompt_template, sentence_text, remove_input=True):\n",
    "    device = \"cuda:0\"\n",
    "    full_prompt = prompt_template.format(sentence_text)\n",
    "\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens=len(sentence_text))\n",
    "    # outputs = model.generate(**inputs, max_new_tokens=len(sentence_text), do_sample=True, top_k=30, top_p=0.95, num_return_sequences=1) # for translation, https://huggingface.co/docs/transformers/tasks/translation#inference\n",
    "\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    if remove_input:\n",
    "        # 從 generate 出來的 output 中刪除 input text 的部分\n",
    "        cleaned_output = decoded_output.replace(full_prompt, \"\")\n",
    "        return cleaned_output\n",
    "    else:\n",
    "        return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我國古代品評書畫藝術的三個等級，即神品、妙品、能品。\n",
      "##\n",
      "---\n",
      "台中后里位在台湾南北的交会点，隐藏着许多全国知名的景点。\n",
      "### Input:\n",
      "翻\n",
      "---\n",
      "幹什麼不幹你的事。\n",
      "##\n",
      "---\n",
      "我發現太后的頭髮很乾燥。\n",
      "\n",
      "---\n",
      "芋头发芽了。\n",
      "\n",
      "---\n",
      "再坐在電腦前面我頭髮都沒了T_T。\n",
      "### Input\n",
      "---\n",
      "他覺得醜時人生的通常比較醜。\n",
      "### Inst\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# load 完之後希望是可以翻譯的\n",
    "sentence = \"我国古代品评书画艺术的三个等级，即神品、妙品、能品。\"\n",
    "sentence1 = \"台中后里位在台湾南北的交会点，隐藏着许多全国知名的景点。\"\n",
    "sentence2 = \"我干什么不干你事。\"\n",
    "sentence3 = \"我发现太后的头发很干燥。\"\n",
    "sentence4 = \"芋头发芽了。\"\n",
    "sentence5 = \"再坐在电脑前面 我头发都没了T_T。\"\n",
    "sentence6 = \"他觉得丑时人生的通常都比较丑。\"\n",
    "\n",
    "translate_prompt_template = \"\"\"\n",
    "### Instruction:\n",
    "翻譯成繁體中文: {}\n",
    "### Response:\n",
    "\"\"\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "print(get_response(model, translate_prompt_template, sentence))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence1))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence2))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence3))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence4))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence5))\n",
    "print('---')\n",
    "print(get_response(model, translate_prompt_template, sentence6))\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Generate:\n",
      "<s>\n",
      "### Instruction:\n",
      "AI是什麼\n",
      "### Response:\n",
      "**人工智能（Artificial Intelligence，简称AI）** 指的是计算机系统具有人类智能\n"
     ]
    }
   ],
   "source": [
    "sentence = \"AI是什麼\"\n",
    "prompt = f'''\n",
    "### Instruction:\n",
    "{sentence}\n",
    "### Response:\n",
    "'''\n",
    "\n",
    "print(\"*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, do_sample=True, top_k=30, top_p=0.95, max_new_tokens=20)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Comment:不,我是一個人類。佷謝問. ��\n"
     ]
    }
   ],
   "source": [
    "sentence = \"你好 你是誰\"\n",
    "prompt = f\"\"\"\n",
    "### Instruction:\n",
    "{sentence}\n",
    "### Response:\n",
    "\"\"\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    do_sample=True, top_k=30, top_p=0.95,\n",
    "    max_new_tokens=20\n",
    ")\n",
    "\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# 從 generate 出來的 output 中刪除 input text 的部分\n",
    "cleaned_output = decoded_output.replace(prompt, \"\").strip()\n",
    "print(cleaned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ff1fb7e1820c5a4d\n",
      "Found cached dataset parquet (/home/wirl/.cache/huggingface/datasets/parquet/default-ff1fb7e1820c5a4d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test dataset---\n",
      "Dataset({\n",
      "    features: ['en', 'ch'],\n",
      "    num_rows: 310916\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# TODO: 怎麼拿到測試資料 (參見 onenote 筆記)\n",
    "test_dataset = load_dataset('parquet', data_files='corpus/_正體(繁體)/zetavgcoct_en-zh-tw-translations-twp-300k.parquet', split='train')\n",
    "\n",
    "print(\"---Test dataset---\")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While the China Times Group has decided to dro...</td>\n",
       "      <td>而在中時報系以不堪虧損為由捨棄晚報的同時，另方面卻持續入股中天電視台，並有意在未來收購中視，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The ten years after the war were a golden age ...</td>\n",
       "      <td>終戰後的十餘年間，可說是歌仔戲的黃金時代，人才輩出，除了活躍於戲院舞台的「內台戲」外，還有「...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Civilian art, which is characterized by its no...</td>\n",
       "      <td>「國民美術」以非學院派美術基調的發展過程，巧妙地與 1998 年國內社區大學興起的「解放知識...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Civilian Art is like a harvest festival in wh...</td>\n",
       "      <td>汐止社大主任潘英海表示：「國民美術像集體參與的美術豐年祭，劉秀美在社區成立畫會，建構集體記憶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For example, Zheng Jionghui's grandfather ran ...</td>\n",
       "      <td>例如日治時期祖父在金瓜石經營「鈔利搗礦場」的鄭炯輝，將當時用水車淘洗金砂的過程，一一用圖畫記...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310911</th>\n",
       "      <td>Who can resist capitalism?</td>\n",
       "      <td>誰來對抗資本主義？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310912</th>\n",
       "      <td>I was terribly scared! \"</td>\n",
       "      <td>在西畫荒漠中披荊斬棘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310913</th>\n",
       "      <td>I'm scared! \"</td>\n",
       "      <td>我怕！」</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310914</th>\n",
       "      <td>How subjective and arrogant that is!</td>\n",
       "      <td>多麼主觀傲慢！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310915</th>\n",
       "      <td>Swaziland Learns from the ROC</td>\n",
       "      <td>不只是給一條魚﹘﹘中華民國駐史瓦濟蘭技術服務</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310916 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       en  \\\n",
       "0       While the China Times Group has decided to dro...   \n",
       "1       The ten years after the war were a golden age ...   \n",
       "2       Civilian art, which is characterized by its no...   \n",
       "3       \"Civilian Art is like a harvest festival in wh...   \n",
       "4       For example, Zheng Jionghui's grandfather ran ...   \n",
       "...                                                   ...   \n",
       "310911                         Who can resist capitalism?   \n",
       "310912                           I was terribly scared! \"   \n",
       "310913                                      I'm scared! \"   \n",
       "310914               How subjective and arrogant that is!   \n",
       "310915                      Swaziland Learns from the ROC   \n",
       "\n",
       "                                                       ch  \n",
       "0       而在中時報系以不堪虧損為由捨棄晚報的同時，另方面卻持續入股中天電視台，並有意在未來收購中視，...  \n",
       "1       終戰後的十餘年間，可說是歌仔戲的黃金時代，人才輩出，除了活躍於戲院舞台的「內台戲」外，還有「...  \n",
       "2       「國民美術」以非學院派美術基調的發展過程，巧妙地與 1998 年國內社區大學興起的「解放知識...  \n",
       "3       汐止社大主任潘英海表示：「國民美術像集體參與的美術豐年祭，劉秀美在社區成立畫會，建構集體記憶...  \n",
       "4       例如日治時期祖父在金瓜石經營「鈔利搗礦場」的鄭炯輝，將當時用水車淘洗金砂的過程，一一用圖畫記...  \n",
       "...                                                   ...  \n",
       "310911                                          誰來對抗資本主義？  \n",
       "310912                                         在西畫荒漠中披荊斬棘  \n",
       "310913                                               我怕！」  \n",
       "310914                                            多麼主觀傲慢！  \n",
       "310915                             不只是給一條魚﹘﹘中華民國駐史瓦濟蘭技術服務  \n",
       "\n",
       "[310916 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert output to pandas dataframe\n",
    "test_dataset.set_format(type='pandas', columns=['en', 'ch'])\n",
    "\n",
    "test_df = test_dataset[:]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'opencc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/wirl/ytc/要寫的論文研究/code/2.3_modeling_test_Chinese_Alpaca2.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B140.124.183.34/home/wirl/ytc/%E8%A6%81%E5%AF%AB%E7%9A%84%E8%AB%96%E6%96%87%E7%A0%94%E7%A9%B6/code/2.3_modeling_test_Chinese_Alpaca2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopencc\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.124.183.34/home/wirl/ytc/%E8%A6%81%E5%AF%AB%E7%9A%84%E8%AB%96%E6%96%87%E7%A0%94%E7%A9%B6/code/2.3_modeling_test_Chinese_Alpaca2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m t2s_converter \u001b[39m=\u001b[39m opencc\u001b[39m.\u001b[39mOpenCC(\u001b[39m'\u001b[39m\u001b[39mt2s.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.124.183.34/home/wirl/ytc/%E8%A6%81%E5%AF%AB%E7%9A%84%E8%AB%96%E6%96%87%E7%A0%94%E7%A9%B6/code/2.3_modeling_test_Chinese_Alpaca2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"traditional chinese to simplified chinese\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'opencc'"
     ]
    }
   ],
   "source": [
    "import opencc\n",
    "\n",
    "t2s_converter = opencc.OpenCC('t2s.json')\n",
    "\n",
    "\"\"\"traditional chinese to simplified chinese\"\"\"\n",
    "def convert_TC_to_SC(zhtw_text: str, converter=None):\n",
    "    if not converter:\n",
    "        converter = opencc.OpenCC('t2s.json')\n",
    "    return converter.convert(zhtw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe98399aca0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/opencc/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe98399afa0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/opencc/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe98393d430>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/opencc/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe98393d5e0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/opencc/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe98393d790>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/opencc/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencc (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for opencc\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install opencc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 怎麼讓他有 history\n",
    "# TODO: 到底什麼是 QLoRA，怎麼實作 => load model in 4bit and merge with lora weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
